[{"content":"\nWhy I Picked It Up I picked up Digital Minimalism because I often felt drained after hours of scrolling, yet I did not want to cut myself off from the benefits of technology. I wanted a system that would help me stay connected without losing focus and peace of mind. Newport’s book turned out to be exactly that kind of guide.\nThe book is divided into two parts: Foundations (where the importance of digital minimalism in living a healthy life is explained) and Practices (where actionable strategies are shared).\nThe Digital Decluttering Newport provides practical steps to make minimalism actionable. These include:\nCleaning up social media Limiting Twitter and Reddit to purposeful use Planning seasonal or weekly leisure that is structured and meaningful Low vs High Leisure Newport draws a sharp line between passive leisure and high-value leisure.\nPassive leisure → endless scrolling, binge content High-value leisure → building, learning, creating something tangible High-value leisure brings real satisfaction and long-term rewards.\nSpend Time Alone The book highlights the importance of solitude, not as isolation but as a healthy space to think, process, and recharge. In a world of constant input, this reminder feels powerful.\nSlow Media Instead of chasing constant updates, Newport recommends slowing down news consumption. A weekly deep dive into reliable reporting gives a clearer and calmer picture than skimming through every headline or notification.\nThe Last Chapter: Join The Attention Resistance The final chapter makes a strong case for keeping your social media circle small and intentional. Newport suggests adding only people you know closely and skipping endless meme pages or celebrity accounts.\nYou don’t need to chase them; that content will find you anyway. A focused feed removes distraction and makes your online time more valuable.\nFinal Thoughts What I loved most is how well these lessons fit into modern life. They make it easier to step out of the online bubble without feeling left out.\nDigital Minimalism is refreshing, practical, and a must-read for anyone seeking clarity and balance in a noisy world. Newport, a computer science professor, isn’t against digital media but advocates for better use of it.\n","permalink":"http://t3hami.github.io/books/1-digital-minimalism/","summary":"\u003cp\u003e\u003cimg alt=\"Book Cover\" loading=\"lazy\" src=\"/books/1-digital-minimalism/cover.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"why-i-picked-it-up\"\u003eWhy I Picked It Up\u003c/h2\u003e\n\u003cp\u003eI picked up \u003cem\u003eDigital Minimalism\u003c/em\u003e because I often felt drained after hours of scrolling, yet I did not want to cut myself off from the benefits of technology. I wanted a system that would help me stay connected without losing focus and peace of mind. Newport’s book turned out to be exactly that kind of guide.\u003c/p\u003e\n\u003cp\u003eThe book is divided into two parts: \u003cstrong\u003eFoundations\u003c/strong\u003e (where the importance of digital minimalism in living a healthy life is explained) and \u003cstrong\u003ePractices\u003c/strong\u003e (where actionable strategies are shared).\u003c/p\u003e","title":"Book Review: Digital Minimalism by Cal Newport"},{"content":"✨ A short but memorable getaway to Chicago ✨\nStay: ACME Hotel, Downtown Chicago\nDates: Saturday 21st June 2025 to Tuesday 24th June 2025\nSaturday: Arrival and First Impressions We landed in Chicago around 1:45 PM after a morning flight from Dallas. From the airport, we used the CTA (Ventra card makes it super convenient) and reached ACME Hotel downtown by 4:00 PM.\nIn the evening, we joined the Architecture River Cruise at golden hour. The city looked stunning as the lights came on and the skyline reflected in the river. It was the perfect start to the trip.\nSunday: Towers, Art and Fountain Lights We started the day with a 30-minute walk through the city to reach the Willis Tower again, this time to see it in the morning light. From there, we stopped at a Turkish restaurant nearby for a hearty breakfast with fresh bread, eggs, tea, and an authentic touch of home-style flavors.\nNext, we spent several hours at the Art Institute of Chicago. The museum was a treasure trove, but one highlight for me was the sculpture of Marcus Aurelius. As someone who appreciates Stoic philosophy, standing in front of that sculpture felt like connecting with centuries of wisdom and resilience.\nIn the afternoon, we rested in the hotel after so much walking.\nLater in the evening, we headed to Buckingham Fountain for the light show. Watching the fountain dance with the city skyline behind it was beautiful and relaxing.\nMonday: Beach, Food and Night Views We began the day with a walk along Ohio Street Beach before continuing to Navy Pier. The June heat made the lakefront especially refreshing. The water was fresh, not salty as I first assumed it might be, since Lake Michigan is part of the Great Lakes system and filled by glacial meltwater, not the ocean.\nWe booked an umbrella and beach seats, and honestly, I just wanted to stay in the water all day. The cool breeze and chill waves made it one of the highlights of the trip. Navy Pier itself added to the atmosphere with its open spaces and lakefront vibe.\nAfter some rest at the hotel, dinner was at Al-Diar Mandi, where we enjoyed Yemeni cuisine, hearty and full of flavor. The night ended with a trip up to 360 Chicago, soaking in sparkling city views from above.\nTuesday: Wrapping Up On our last day, we visited the Shedd Aquarium late in the morning. It was more than just walking through exhibits, the highlight was the dolphin show. Watching dolphins leap, spin, and glide in perfect coordination was a wonderful way to wrap up the trip.\nAfterward, we checked out from the hotel, collected our luggage, and headed to the airport for our evening flight back to Dallas.\nExtra Notes For transport, we mostly relied on Uber and the CTA with Ventra, which covered almost everything. Meals were a mix of dining out and Uber Eats for convenience. Staying inside downtown made everything accessible. If you are only in the downtown area, you do not need a vehicle. It is actually more convenient not to have one because parking is expensive and unnecessary. Even simple things like water were pricey. The hotel charged per bottle, which made us wonder why most American hotels do not provide complimentary water in the rooms. It was a short but eventful trip, blending culture, food, and cityscapes. Chicago left us with some great memories, and a reminder that water should not feel like a luxury in hotels.\n","permalink":"http://t3hami.github.io/travel/2025-06-chicago-trip/","summary":"\u003cp\u003e✨ A short but memorable getaway to Chicago ✨\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStay:\u003c/strong\u003e ACME Hotel, Downtown Chicago\u003cbr\u003e\n\u003cstrong\u003eDates:\u003c/strong\u003e Saturday 21st June 2025 to Tuesday 24th June 2025\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"saturday-arrival-and-first-impressions\"\u003eSaturday: Arrival and First Impressions\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Chicago Skyline\" loading=\"lazy\" src=\"/travel/2025-06-chicago-trip/skyline.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eWe landed in Chicago around 1:45 PM after a morning flight from Dallas. From the airport, we used the CTA (Ventra card makes it super convenient) and reached ACME Hotel downtown by 4:00 PM.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"River\" loading=\"lazy\" src=\"/travel/2025-06-chicago-trip/river.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eIn the evening, we joined the \u003cstrong\u003eArchitecture River Cruise\u003c/strong\u003e at golden hour. The city looked stunning as the lights came on and the skyline reflected in the river. It was the perfect start to the trip.\u003c/p\u003e","title":"Chicago Trip Tour Diary"},{"content":"Email\nt3hami [at] gmail [dot] com (obfuscated to reduce spam; replace [at] and [dot])\nLinkedIn\nMuhammad Tehami\nGitHub\ngithub.com/t3hami\nTwitter\n@MuhammadTehami\nTime Zone\nCurrent Date \u0026amp; Time in My Time Zone (Central): ","permalink":"http://t3hami.github.io/contact/","summary":"\u003cp\u003e\u003cstrong\u003eEmail\u003c/strong\u003e\u003cbr\u003e\nt3hami [at] gmail [dot] com \u003cem\u003e(obfuscated to reduce spam; replace [at] and [dot])\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLinkedIn\u003c/strong\u003e\u003cbr\u003e\n\u003ca href=\"https://linkedin.com/in/t3hami\"\u003eMuhammad Tehami\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGitHub\u003c/strong\u003e\u003cbr\u003e\n\u003ca href=\"https://github.com/t3hami\"\u003egithub.com/t3hami\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTwitter\u003c/strong\u003e\u003cbr\u003e\n\u003ca href=\"https://twitter.com/MuhammadTehami\"\u003e@MuhammadTehami\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTime Zone\u003c/strong\u003e\u003cbr\u003e\nCurrent Date \u0026amp; Time in My Time Zone (Central): \u003cspan id=\"clock\"\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cscript\u003e\n  function updateClock() {\n    const options = {\n      year: 'numeric', month: 'short', day: 'numeric',\n      hour: '2-digit', minute: '2-digit', second: '2-digit',\n      timeZone: 'America/Chicago', timeZoneName: 'short'\n    };\n    const clock = document.getElementById(\"clock\");\n    if (clock) {\n      clock.textContent = new Date().toLocaleString(\"en-US\", options);\n    }\n  }\n  setInterval(updateClock, 1000);\n  updateClock();\n\u003c/script\u003e","title":"Contact \u0026 Social"},{"content":"Professional Background\nDevOps \u0026amp; Cloud Engineer at Nisum, with experience in Linux, Kubernetes, Terraform, and multiple cloud platforms.\nCertified Google Cloud Associate Engineer and Microsoft Azure Administrator.\nLearning \u0026amp; Growth\nCurrently focusing on operating systems internals and distributed systems to strengthen technical fundamentals.\nHealth \u0026amp; Fitness\nCommitted to balancing work and health, training for a 5K under 30 minutes while maintaining strength through barbell lifts.\nWriting \u0026amp; Sharing\nWrites about DevOps, cloud engineering, and productivity, as well as book reviews and travel experiences.\nTravel \u0026amp; Exploration\nEnjoys exploring the world, from national parks and scenic trails to international destinations, with an interest in culture, nature, and adventure.\nCollaboration\nOpen to working on open-source DevOps tools and cloud-native projects.\n","permalink":"http://t3hami.github.io/about/","summary":"\u003cp\u003e\u003cstrong\u003eProfessional Background\u003c/strong\u003e\u003cbr\u003e\nDevOps \u0026amp; Cloud Engineer at Nisum, with experience in Linux, Kubernetes, Terraform, and multiple cloud platforms.\u003cbr\u003e\nCertified Google Cloud Associate Engineer and Microsoft Azure Administrator.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLearning \u0026amp; Growth\u003c/strong\u003e\u003cbr\u003e\nCurrently focusing on operating systems internals and distributed systems to strengthen technical fundamentals.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHealth \u0026amp; Fitness\u003c/strong\u003e\u003cbr\u003e\nCommitted to balancing work and health, training for a 5K under 30 minutes while maintaining strength through barbell lifts.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eWriting \u0026amp; Sharing\u003c/strong\u003e\u003cbr\u003e\nWrites about DevOps, cloud engineering, and productivity, as well as book reviews and travel experiences.\u003c/p\u003e","title":"About Tehami"},{"content":"Jenkins Jenkins is a server for automation that is free and open source. By automating the software development process, enterprises can save time and money. Jenkins is a tool that manages and controls software delivery processes across the whole lifecycle, including build, document, test, package, stage, deployment, static code analysis, and more.\nA typical Jenkins running in any organization looks like the above diagram. But there are multiple problems with the above architecture.\nOnce you have set up the Agent it is continuously running and has acquired resources. If CI increases change you have to add additional agent and vice versa. If any new tool requirement comes; you have to add that tool into the existing agent or add a new agent with the tool installed in it. We can eliminate the above problems if we are using Kubernetes and use the existing cluster for our builds by integrating it with Jenkins. Then we can use on-demands agents as Kubernetes pods.\nWhat Do You Need? Docker Minikube Setting Up Environment Setup Jenkins Create a Jenkins instance by running the following command:\n$ docker run -d --name jenkins -p 8080:8080 -p 50000:50000 jenkins/jenkins:lts Go to http://localhost:8080 and wait for the following screen to come:\nNow run the following command to get the initial admin password from the Jenkins container:\n$ docker exec -it jenkins cat /var/jenkins_home/secrets/initialAdminPassword Now copy the output and paste it on the Jenkins UI.\nSelect “Install suggested plugins” and wait for all plugins to install.\nFill in the user details.\nNow go to Manage Jenkins -\u0026gt; Manage Plugins -\u0026gt; Available. Search Kubernetes and select Kubernetes. Then click on Install without restart.\nCheck “Restart Jenkins when installation is complete and no jobs are running” on the next page.\nWe have our Jenkins up and running with the Kubernetes cloud plugin.\nSetup Minikube and Credentials Start Minikube\n$ minikube start Create a namespace for Jenkins agents.\n$ kubectl create ns jenkins Open ~/.kube/config file. The contents of this file should look like something similar to the following:\napiVersion: v1 clusters: - cluster: certificate-authority: ~/.minikube/ca.crt extensions: - extension: last-update: Sat, 19 Dec 2021 22:20:16 PKT provider: minikube.sigs.k8s.io version: v1.20.0 name: cluster_info server: https://192.168.99.103:8443 name: minikube contexts: - context: cluster: minikube extensions: - extension: last-update: Sat, 19 Dec 2021 22:20:16 PKT provider: minikube.sigs.k8s.io version: v1.20.0 name: context_info namespace: default user: minikube name: minikube current-context: minikube kind: Config preferences: {} users: - name: minikube user: client-certificate: ~/.minikube/profiles/minikube/client.crt client-key: ~/.minikube/profiles/minikube/client.key Copy all the contents in a different file and replace certificate-authority, client-certificate, and client-key with certificate-authority-data, client-certificate-data, and client-key-data respectively. For values of these keys, we need base64 encoded data of the actual file reference. Repeat the following step for all three keys with their respective file and paste the output as a value.\n$ cat ~/.minikube/ca.crt | base64 $ cat ~/.minikube/profiles/minikube/client.crt | base64 $ cat ~/.minikube/profiles/minikube/client.key | base64 The final file should look similar to the following file:\napiVersion: v1 clusters: - cluster: certificate-authority-data: \u0026lt;base64_encoded_string\u0026gt; extensions: - extension: last-update: Sat, 19 Dec 2021 22:20:16 PKT provider: minikube.sigs.k8s.io version: v1.20.0 name: cluster_info server: https://192.168.99.103:8443 name: minikube contexts: - context: cluster: minikube extensions: - extension: last-update: Sat, 19 Dec 2021 22:20:16 PKT provider: minikube.sigs.k8s.io version: v1.20.0 name: context_info namespace: default user: minikube name: minikube current-context: minikube kind: Config preferences: {} users: - name: minikube user: client-certificate-data: \u0026lt;base64_encoded_string\u0026gt; client-key-data: \u0026lt;base64_encoded_string\u0026gt; Go to Manage Jenkins -\u0026gt; Manage Credentials -\u0026gt; Global credentials -\u0026gt; Add Credentials. Select Kind as Secret file, Choose the file to upload we created earlier, give any ID e.g. minikube-kubeconfig. Hit OK to create.\nConfigure Kubernetes Cloud in Jenkins Go to Manage Jenkins -\u0026gt; Manage Node and Cloud -\u0026gt; Configure Clouds -\u0026gt; Add a new cloud -\u0026gt; Kubernetes -\u0026gt; Kubernetes Cloud Details.\nSelect Credentials created in the previous step and click Test Connection.\nSave cloud and add a new pod template for Jenkins agent default pod. Click on Pod template details… as follows:\nHit Save.\nGo to Manage Jenkins -\u0026gt; Configure System -\u0026gt; Jenkins URL and put your private IP in there.\nHit Save.\nRunning First Build using On-Demand Agent as Kubernetes Pod Open Jenkins dashboard and create a new pipeline with following content:\npipeline { agent { label \u0026#39;k8s-build-1\u0026#39; } stages { stage(\u0026#39;Test Build\u0026#39;) { steps { println \u0026#39;Hello World from Kubernetes Pod!\u0026#39; sh \u0026#39;hostname\u0026#39; } } } } Now run your first pipeline and check logs\nConclusion Currently, our Jenkins on-demand agent running as Kubernetes pod is using jenkins/inbound-agent:4.11–1-jdk11 image. We can create multiple customized images using this image as a base for our required needs and create multiple pod templates with different labels for different CI requirements.\n","permalink":"http://t3hami.github.io/tech/post_4/","summary":"\u003ch2 id=\"jenkins\"\u003eJenkins\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Jenkins Architecture\" loading=\"lazy\" src=\"/images/posts/post_4/jenkins-architecture.png\"\u003e\u003c/p\u003e\n\u003cp\u003eJenkins is a server for automation that is free and open source. By automating the software development process, enterprises can save time and money. Jenkins is a tool that manages and controls software delivery processes across the whole lifecycle, including build, document, test, package, stage, deployment, static code analysis, and more.\u003c/p\u003e\n\u003cp\u003eA typical Jenkins running in any organization looks like the above diagram. But there are multiple problems with the above architecture.\u003c/p\u003e","title":"Jenkins On-Demand Agents"},{"content":"What is Autoscaling? Automatic scaling, is a cloud computing strategy that dynamically modifies the amount of computational resources required for an application. Normally measured by the number of active servers based on the load on the farm. For example, the number of servers hosting a web application can automatically increase or decrease based on the number of active users on your site. Because such metrics can fluctuate substantially during the day, and servers are a limited resource that cost money to run even when inactive, there is often an incentive to run “just enough” servers to support the current demand while still being able to handle sudden and large surges in activity. Autoscaling is useful for such situations because it may reduce the number of active servers when activity is low, and it can also increase the number of active servers when activity is high.\nBefore moving ahead to deploy our application on Kubernetes and Autoscale it, there are a couple of terms we need to be familiar with.\nInstance: A single server or machine that is in itself is an independent unit or we can say microservice. Autoscaling Group: The set of instances that are subject to autoscaling, as well as all associated policies and state data. Size: The number of instances in the autoscaling group at the moment. Desired Size: At any given time, the number of instances that the autoscaling group should have. The autoscaling group will try to launch (provision and attach) new instances if the size is less than the intended size. The autoscaling group will try to eliminate (detach and terminate) instances if the size exceeds the specified size. Minimum Size: The number of instance from which the targeted capacity is not allowed to go below. Maximum Size: The number of instance from which the targeted capacity is not allowed to go beyond. Metric: A measurement connected with the autoscaling group for which a time series of data points is created on a regular basis (such as CPU use, memory consumption, and network usage). Metric thresholds can be used to create autoscaling policies. Autoscaling Policy: In response to metrics reaching particular thresholds, a policy that specifies a modification to the autoscaling group’s targeted capacity (or, in some cases, its minimum and maximum size). Cooldown periods can be connected with scaling policies, preventing future scaling actions from occurring shortly after one. Changes to intended capacity could be incremental (increasing or decreasing by a specified number) or give a new desired capacity value. Policies that enhance desired capacity are referred to as “scaling out” or “scaling up,” while policies that reduce desired capacity are referred to as “scaling in” or “scaling down”. Vertical Scaling: Vertical scaling preserves your current infrastructure while increasing processing power. All you have to do is run it on an existing number of machines but with improved specs. By scaling up, you can improve the capacity and throughput of a single system. . Horizontal Scaling: Horizontal scaling increases the number of machine instances without improving the existing specs. Scale out to distribute processing power and load balancing across multiple servers. We will mainly focus on Horizontal Scaling in this article.\nSetting Up Environment Minikube Minikube is a local Kubernetes that focuses on making Kubernetes easy to learn and develop locally. Kubernetes is only a single command away if you have Docker (or similarly compatible) container tooling or a Virtual Machine environment. Head to the following docs: https://minikube.sigs.k8s.io/docs/start/\nKubectl Kubernetes clusters can be managed through the kubectl command line tool. https://minikube.sigs.k8s.io/docs/handbook/kubectl/\nNow we have minikube and kubectl to control our cluster from cli let’s start our very first Kubernetes Cluster:\n$ minikube start Deploying Nginx Server on Kubernetes Let’s deploy an application on Kubernetes. For the demo purpose we are using the most simplest of the deployment; an Nginx server.\nCreate autoscale namespace.\n$ kubectl create ns autoscale Create nginx-deployment.yaml file with following content:\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment namespace: autoscale spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 resources: requests: cpu: 250m memory: 100Mi limits: cpu: 300m memory: 150Mi Create deployment\n$ kubectl apply -f nginx-deployment.yaml Now we have to expose our application using NodePort service. Create nginx-service.yaml file with following content:\napiVersion: v1 kind: Service metadata: name: nginx namespace: autoscale labels: app: nginx spec: type: NodePort ports: - port: 8080 nodePort: 31934 targetPort: 80 protocol: TCP name: http selector: app: nginx Create service\n$ kubectl apply -f nginx-service.yaml Verify the Nginx server started and can be accessed using configured Node Port\n$ curl http://`minikube ip`:31934 We have successfully deployed a Nginx server on our Kubernetes Cluster. Now the problem is if our application starts getting a lot of traffic it’s performance will start to decline as there is only one replica(instance) of our deployment(application) running in the cluster. We can manually update the number of replicas in our deployment before peak hours but then it will be unnecessary use of resources during the time there is very less traffic.\nAutoscaling with Kubernetes Metric Server For Kubernetes built-in autoscaling pipelines, Metrics Server offers a scalable and efficient source of container resource metrics.\nThe Metrics API in the Kubernetes apiserver collects resource metrics from Kubelet and makes them available to Horizontal Pod Autoscaler and Vertical Pod Autoscaler. kubectl top may also access the metrics API.\nInstalling Metric Server By default there is no metric server installed in Cluster created by Minikube. Install the metric server using the following command:\n$ minikube addons disable heapster $ minikube addons enable metrics-server Note: Use following Helm Chart to install Metric Server if you are not using Minikube: https://github.com/kubernetes-sigs/metrics-server/tree/master/charts/metrics-server\nValidate Metric Server is running\n$ kubectl get po -n kube-system NAME READY STATUS RESTARTS AGE coredns-74ff55c5b-x42f6 1/1 Running 0 1d etcd-minikube 1/1 Running 0 1d kube-apiserver-minikube 1/1 Running 0 1d kube-controller-manager-minikube 1/1 Running 0 1d kube-proxy-k87m2 1/1 Running 0 1d kube-scheduler-minikube 1/1 Running 0 1d metrics-server-7894db45f8-wxzqd 1/1 Running 0 3m storage-provisioner 1/1 Running 0 1d Create nginx-autoscale.yaml with following content\napiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: nginx-autoscale namespace: autoscale spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: nginx-deployment minReplicas: 1 maxReplicas: 10 metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 50 Now create Horizontal Pod Autoscaler\n$ kubectl apply -f nginx-autoscale.yaml Check current metrics\n$ kubectl top pod -n autoscale NAME CPU(cores) MEMORY(bytes) nginx-deployment-67459f4f86-6hq6g 0m 2Mi There is only one pod running which is very obvious as we can see there’s no traffic currently coming to the Nginx server.\nCreating Load With Apache Bench The Apache Bench(ab) is a load testing and benchmarking tool for HTTP servers. It’s easy to use and may be started from the terminal. Install for your platform: https://httpd.apache.org/docs/2.4/programs/ab.html\nVerify that you have it working by checking Apache Bench version.\n$ ab -V Now open two terminals\n1st terminal to monitor pods and their resource usage\n$ watch kubectl top pod -n autoscale 2nd terminal to send load to Nginx using Apache Bench. Here we are sending a total of 200000 requests and 200 concurrent requests. This will generate enough load to increase CPU utilization above 50%.\nab -n 200000 -c 200 http://`minikube ip`:31934/ Soon you will see the surge in resource usage and pods getting autoscale. In my machine the number of pods increased to 4.\n$ NAME CPU(cores) MEMORY(bytes) nginx-deployment-67459f4f86-6hq6g 139m 2Mi nginx-deployment-67459f4f86-h6f5m 116m 2Mi nginx-deployment-67459f4f86-jt66v 52m 2Mi nginx-deployment-67459f4f86-x55gv 56m 2Mi Once all requests are completed the pods will downscale to 1 again.\nConclusion Kubernetes Horizontal Autoscaling takes care of up scaling and down scaling pods based on the resource usage metrics specified. It eliminates the need of manually changing the configuration to meet the current resource usage demand.\n","permalink":"http://t3hami.github.io/tech/post_3/","summary":"\u003ch2 id=\"what-is-autoscaling\"\u003eWhat is Autoscaling?\u003c/h2\u003e\n\u003cp\u003eAutomatic scaling, is a cloud computing strategy that dynamically modifies the amount of computational resources required for an application. Normally measured by the number of active servers based on the load on the farm. For example, the number of servers hosting a web application can automatically increase or decrease based on the number of active users on your site. Because such metrics can fluctuate substantially during the day, and servers are a limited resource that cost money to run even when inactive, there is often an incentive to run “just enough” servers to support the current demand while still being able to handle sudden and large surges in activity. Autoscaling is useful for such situations because it may reduce the number of active servers when activity is low, and it can also increase the number of active servers when activity is high.\u003c/p\u003e","title":"Understand Autoscaling Applications In Kubernetes Before Next Peak Hours"},{"content":"Overview Git Git is a crucial part of every developer’s life. We have come across from the cumbersome and hectic usage of bad old days versioning practice to a centralized and easy to collaborate process with git.\nAs the versioning became easier and collaboration is on our fingertips, there comes the issue of authenticity of the work contributed by individuals.\nThe Donkey in Lion’s Skin We all have heard the The Donkey in Lion’s Skin story. The TLDR is a donkey dressed itself in a lion’s skin. Wherever the donkey went, the other animals and villagers feared him. The villagers and other animals thought that he was a real lion. After some time he became bold. Finally one day some people heard him braying. The people ran after him with sticks, and beat him to death. Hence, the poor donkey paid the price for his foolishness.\nBut what does the donkey story have to do with git? In git, a single contribution is called a commit which holds all the meta data regarding the work being done and by whom. The user meta data which is name and email address are associated with every commit. The problem with this is that anyone can add any user and email address to commit even if the email doesn’t belong to that user.\nPublic-key cryptography A type of cryptography which uses a pair of keys, a public key and a private key; the two keys have the related in a way that, given the public key, it is computationally infeasible to derive the private key. For connection establishment, public-key cryptography enables different parties to communicate securely without having prior access to a secret key (unlike symmetric key cryptography which only involves one key) that is shared, by using one or more pairs (public key and private key) of cryptographic keys. There are lot of tools which implement public key cryptography. One of them is GPG.\nPGP, OpenPGP, GPG Back in 1990s Phil Zimmermann created a data encryption and decryption computer program called Pretty Good Privacy (PGP) which is currently owned by software security company Symantec. Soon PGP become the de-facto standard in e-mail communication. PGP is a commercial product, and as the opensource software boomed the need for the opensource alternatives to the PGP became inevitable. This gave birth to OpenPGP which is an open source standard that allows PGP to be used in software that is typically free to the public. The term “Open PGP” is often applied to tools, features, or solutions that support open-source PGP encryption technology. GPG is an implementation of the Open PGP standard. The GPG, or GnuPG, stands for GNU Privacy Guard.\nBack To The Terminal Install GPG Install GPG depending on the OS you are using: https://gnupg.org/download/\nAfter the installation, verify that you have it working:\ngpg --version Creating GPG keypair gpg --full-generate-key Now an interactive console will ask some information.\nUse option one (1) RSA and RSA (default), give key size (ideally 4096), set expiry date for example 1y, give your real name and email address and comment (optional).\nAfter this GPG will perform some math behind the key generation which uses some big random prime numbers. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy.\nI use dd(copy files) and rngd(a random number generator) on linux. You can use any program which does a lot of cpu processing and uses hard drive (Chrome included :D). Use following if you are on server which can’t get enough entropy.\nsudo yum install rng-tools sudo systemctl start rngd sudo dd if=/dev/sda of=/dev/zero Now we have our gpg keypair ready to use. Verify that the key is created successfully:\ngpg --list-keys Sign git commit Make sure your name and email in git configuration is same as you have in the gpg key:\ngit config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;Your Email\u0026#34; Create a directory and initialize git:\nmkdir repo cd repo git init Stage a file:\ntouch file git add file Now create a signed commit:\ngit commit -S -m \u0026#34;My signed commit\u0026#34; Check the signed commit:\ngit log --show-signature You successfully signed commit with your private GPG key.\nDistributing public GPG key It’s time to distribute your public key so that others will know that the commit was actually signed by your private key.\nGet your public key:\ngpg --export --armor \u0026#34;Your Email\u0026#34; Copy the output and go to:\nGithub -\u0026gt; settings -\u0026gt; SSH and GPG keys.\nClick on New GPG Keys button and paste you public key. Click Add GPG key button.\nAfter doing above when you push the code to Github it will show a verified badge against your commit, which shows that this key was actually signed by the corresponding private key of the given public key in Github.\nCaveat When you don’t provide the -S flag in git commit it’ll not sign the commit. If you want to sign every commit without providing the -S flag explicitly, then modify your global git config file as follows:\nOpen git config file from ~/.gitconfig and add following lines in it.\n[commit] gpgsign = true [tag] gpgsign = true You can now use usual git commit to create signed commits.\ngit commit -m \u0026#34;Signed commit without -S\u0026#34; Now what? Remember that donkey in lion’s skin. Well we don’t have to worry now :D\nThanks for following along, take a look at GPG cheat sheet I’ve created:\nhttps://github.com/t3hami/GPG-cheat-sheet.git\n","permalink":"http://t3hami.github.io/tech/post_2/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"Git GPG\" loading=\"lazy\" src=\"/images/posts/post_2/git-gpg.jpeg\"\u003e\u003c/p\u003e\n\u003ch3 id=\"git\"\u003eGit\u003c/h3\u003e\n\u003cp\u003eGit is a crucial part of every developer’s life. We have come across from the cumbersome and hectic usage of bad old days versioning practice to a centralized and easy to collaborate process with git.\u003c/p\u003e\n\u003cp\u003eAs the versioning became easier and collaboration is on our fingertips, there comes the issue of authenticity of the work contributed by individuals.\u003c/p\u003e\n\u003ch3 id=\"the-donkey-in-lions-skin\"\u003eThe Donkey in Lion’s Skin\u003c/h3\u003e\n\u003cp\u003eWe all have heard the The Donkey in Lion’s Skin story. The TLDR is a donkey dressed itself in a lion’s skin. Wherever the donkey went, the other animals and villagers feared him. The villagers and other animals thought that he was a real lion. After some time he became bold. Finally one day some people heard him braying. The people ran after him with sticks, and beat him to death. Hence, the poor donkey paid the price for his foolishness.\u003c/p\u003e","title":"Signing Git Commits with GPG"},{"content":"Overview Shipping your application in containers is a new norm and CI/CD is also a must have in today’s development. Here I’ve created a React.js DevOps ready application for reference of those who are new to Containers and CI/CD.\nDocker Docker is for managing container. Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and deploy it as one package.\nReact.js React.js is a JavaScript library used in web development to build interactive elements on websites.\nNGINX NGINX is an open source software for web serving, reverse proxying, caching, load balancing, media streaming, and more.\nContainerising React.js Application Create a react application with create-react-app cli\n$ create-react-app react-containerize package.json\n{ \u0026#34;name\u0026#34;: \u0026#34;react-containerize\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, .... .... .... \u0026#34;homepage\u0026#34;: \u0026#34;.\u0026#34; } Now create an application build by running npm run build. This will generate a build directory containing all the html, css, js and other static content which can be served from a web server.\n$ npm run build React.js provides single page applications in which all the requests are routed through main index.html page, to configure this we have to add some configuration in our nginx. I’ve created a file called nginx.conf with required configuration.\nnginx.conf\nserver { listen 80; server_name localhost; root /usr/share/nginx/html; location / { try_files $uri $uri/ /index.html; } } Dockerfile Steps:\nUse nginx:alpine as base image Copy build directory to /usr/share/nginx/html Remove default nginx configuration /etc/nginx/conf.d/default.conf Copy our custom nginx configuration for handling routing nginx.conf Dockerfile\nFROM nginx:alpine COPY build /usr/share/nginx/html RUN rm /etc/nginx/conf.d/default.conf COPY nginx.conf /etc/nginx/conf.d Before building image, create a file .dockerignore and add “node_module” in it. When we build docker image, docker creates a context in memory with all the files in the specified context. What .dockerignore do is, it will make docker ignore all the files and folders which are specified in .dockerignore.\n.dockerignore\nnode_modules Now build docker image\n$ docker build -t tehami/react:1.0 . This will create an image named tehami/react with tag 1.0\nPushing Image and Run it Locally You can push your image to docker hub by\n$ docker login $ docker push tehami/react:1.0 Now anyone can start a container using this image by running:\n$ docker run -d -p 80:80 --name react tehami/react:1.0 Github repository: https://github.com/t3hami/react-devops.git\n","permalink":"http://t3hami.github.io/tech/post_1/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eShipping your application in containers is a new norm and CI/CD is also a must have in today’s development. Here I’ve created a React.js DevOps ready application for reference of those who are new to Containers and CI/CD.\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"Docker Nginx React.js\" loading=\"lazy\" src=\"/images/posts/post_1/docker-nginx-react.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"docker\"\u003eDocker\u003c/h3\u003e\n\u003cp\u003eDocker is for managing container. Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and deploy it as one package.\u003c/p\u003e","title":"React.js DevOps Ready Application"}]